### 问题描述：
<p>for循环后,字典内输出内容没有改变</p>
问题:输出的字典内容没有新增,
每一页的内容都应该保存在字典里,
但字典内容输入一直为第一页的内容.
求帮助!!

```python
import requests
import re
class Dytt_pa(object):
    def __init__(self):
        self.file_dict = {}
    def get_page(self,url='https://www.dytt8.net/html/gndy/dyzz/list_23_1.html'): # 定义缺省url为xxx
        """获取电影列表网页源码"""
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.62 Safari/537.36"}
        req = requests.get(url,headers=headers)
        req.encoding = 'GBK'
        return req.text
    def get_film_link(self):
        """将迅雷下载地址与电影名保存到字典中"""
        file_list = re.findall(r'<a href="(.*)" class="ulink">(.*)</a>',self.get_page()) # 得到25个(半个电影link和电影名)的list
        for film_link,film_name in file_list:
            page_heard = "https://www.dytt8.net"
            film_link = page_heard + film_link # list中的完整的电影link
            film_download_text = self.get_page(film_link) # 电影详情页源码
            xun_lei = re.search(r'<td style=".*" bgcolor=".*"><a href="(.*)">ftp',film_download_text).group(1) # 正则出迅雷下载地址
            self.file_dict[film_name] = xun_lei
    def start(self):
        num = int(input("请输入你要下载几页:"))
        for numa in range(1,num+1):
            print("正在下载第%d页,请稍后"%numa)
            self.get_page(url='https://www.dytt8.net/html/gndy/dyzz/list_23_%d.html'%numa)
            self.get_film_link()
            print("已下载完第%d页."%numa)
        for a, b in self.file_dict.items():
            print("%s|%s" % (a, b))


if __name__ == '__main__':
    woyaoxiadiany = Dytt_pa()
    woyaoxiadiany.start()






 
```

### 修改方案：
由于网络原因,这个脚本没有执行成功,看了一下代码,感觉有疑问的地方:
self.get_page 这个页面爬取操作返回的页面文本内容并没有存储,而是在get_film_link里面又重新请求了一次,此时 URL 可能就是默认的第一页,所以没有其他页的内容。
建议修改逻辑如下:

```python
def __init__(self):
        self.file_dict = {}
        self.pageContent = ''

    def get_page(self,url='https://www.dytt8.net/html/gndy/dyzz/list_23_1.html'): # 定义缺省url为xxx
        """获取电影列表网页源码"""
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.62 Safari/537.36"}
        req = requests.get(url,headers=headers)
        req.encoding = 'GBK'
        self.pageContent = req.text

    def get_film_link(self):
        """将迅雷下载地址与电影名保存到字典中"""
        file_list = re.findall(r'<a href="(.*)" class="ulink">(.*)</a>',self.pageContent) # 得到25个(半个电影link和电影名)的list
        for film_link,film_name in file_list:
            page_heard = "https://www.dytt8.net"
            film_link = page_heard + film_link # list中的完整的电影link
            film_download_text = self.get_page(film_link) # 电影详情页源码
            xun_lei = re.search(r'<td style=".*" bgcolor=".*"><a href="(.*)">ftp',film_download_text).group(1) # 正则出迅雷下载地址
            self.file_dict[film_name] = xun_lei

```
用一个变量保存每一页的记录,在解析时直接取该变量的值。
### 人工打分：
